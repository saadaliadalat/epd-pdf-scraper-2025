name: EPD PDF Scraper 2025

on:
  schedule:
    - cron: '0 */3 * * *' # every 3 hours
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: self-hosted
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Try using system Python first
      - name: Check Python version
        run: |
          echo "Using system Python if available..."
          python --version || echo "No system Python found"

      # Fallback if system Python is missing
      - name: Setup Python (Fallback)
        if: ${{ failure() }}
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Upgrade pip & install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp playwright pypdf psutil aiosmtplib
          playwright install --with-deps chromium

      - name: Run scraper
        run: |
          echo "Starting scraper..."
          python scraper.py || { echo "Scraper failed"; exit 1; }

      - name: Commit new PDFs
        run: |
          echo "Checking for new PDFs..."
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          if git ls-files downloaded_pdfs/pdfs/* --error-unmatch > /dev/null 2>&1; then
            git add downloaded_pdfs/pdfs/*
            git commit -m "Auto: Add new EPD PDFs $(date +'%Y-%m-%d %H:%M:%S')" || echo "No new PDFs to commit"
            git push origin main
          else
            echo "No PDFs found to commit"
          fi
